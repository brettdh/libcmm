*** TODO ***

* Look through and make sure all the error-handling looks right; i.e.
  when connectivity with the remote host is lost, all the data structures
  and threads associated with the multi-socket are cleaned up
  and an error is returned to the caller.  Similarly, when physical 
  connections break, their CSockets and associated threads should be
  cleaned up.
  * Question: would it still make sense to keep a multi-socket around
    if there are no interfaces to connect on?  Presumably, if the other
    side keeps my listener port info, it could reconnect and THEN tell me
    about its interfaces.
    * Need to make sure that my code doesn't make any unnecessary
      assumptions that would make this difficult.

* Ensure that connections are gracefully cleaned up upon 
  close() or shutdown(). (DONE)

* Think about and write up a list of sensible ways to handle failures:
  * where all physical connections are broken, but interfaces
    are still available to connect on
  * where all physical connections are broken and no connections are possible

  * ALSO, think about this in terms of the following options for 
    failure notification:
    1) The application wants to ignore failure
    2) The application wants to be notified immediately
    3) The application wants to be notified after a timeout

* Make a more interesting test app with actual reordering and constraints.

* Make a regression test suite. (DONE; the framework, at least,
  with some simple tests.)

* Get rid of the scheduler threads and just have the sender worker thread
  and the application receiver thread make the scheduling decisions
  in a procedure call. (DONE)

* Think about the IROB data structure on the sender and receiver ends,
  especially how to index IROBs.

  * Useful indexes in the sender-side data structure:
    - Put simply, IROBs for which *some* bytes are ready to be sent 
      (whether those bytes are "begin/end" messages, or chunks, or acks).
    - Pending control messages (separate from IROBs).

  * Useful indexes in the receiver-side data structure:
    - IROBs that are ready to be received by the application.
    - IROBs/chunks that haven't been ACK'd.

* Rethink whether using TBB is a good idea.

* Try the throughput experiment with induced latency on a vanilla socket,
  to see whether latency is causing throughput degradation.
  * Prelim: doesn't seem to affect throughput significantly (4ms or 30ms 
    NISTnet latency, comparable to/more than the per-send latency I was
    inducing.)

* This reasonable assumption makes implementation simpler:
   "IROBs may not depend on future IROBs.  Thus, the IROB IDs form
    a partial order over all IROBs."  (DONE; implemented the IROB
       data structure as a std::deque wraapper)

* Figure out which threads are not getting cleaned up, and why. (DONE)

* (DONE)Get rid of recv_labels for cmm_send and the like.  A label applies to
  a connection, not an interface.  This has implications which will 
  play out later, but for now, getting rid of the recv_labels simplifies
  the interface.

* Make cmm_select() work! (DONE, I think.)

* Make sure that concurrent send/recv work, since this is thread-safe for 
  regular sockets.  Also make sure cmm_shutdown is thread-safe with 
  all the other calls. (DONE, but not really; inspected, not tested.)


* Add bandwidth and latency estimates to the CSocket structure.
  The scout will update them periodically. (DONE)


Post-Mobisys TODO items
------------------------
--DONE-- * Fix the round-robin-scheduling bug; an IROB should be sent in its
--DONE--    entirety before moving on to the next IROB of that label.
--DONE-- * Fix the inefficiency in retransmitting lost IROB data; ask the receiver
--DONE--    how much data has been received before retransmitting any.
--DONE-- * Track down and squash the bugs that resulted in very high variance
--DONE--    and sporadic failure in the BlueFS intermittent scenario (due to app-level 
--DONE--    timeouts that shouldn't be happening).

--DONE-- * Debug the existing IMAP caching proxy and get it working for the
--DONE--   current simple no-caching, pass-through sanity check.

* Construct an interesting benchmark for the Thunderbird->IMAPCachingProxy app.
  * Iterate:
    * Build the necessary features in that app.
    * Try it out.
    * Refine the benchmark and the application modifications.
  (DONE.)

* Pick a third mobile application with an interesting use case for IntNW.
  * Iterate:
    * Modify the app as needed.
    * Construct and run a benchmark.
    * Refine the benchmark and the app/use case.
   (DONE, for now.)

* Walking trace, and/or trace with more WiFi? (more WiFi, DONE)

* Understand the real cost of trickling, so that we can make sense of
   our experimental results. (DONE?)

* Make use of all available networks when appropriate.
    (DONE) This means some simple form of striping.



* Figure out a way to make our traffic reordering/prioritizing/trickling
   work for applications with multiple multisockets?  Higher priority if 
   we think our applications will benefit.

* Get a live network test working with active measurements.
  (Once this works, we can run the active measurements also while doing
   the trace-based evaluation.)

* Consider adding irob_cancel and irob_change_label to the API.

* Merge the striping branch.

It-would-be-nice TODOs:

* Swap POSIX message queues for SysV IPC (msgsnd).  Message queues are annoying,
  are not supported everywhere, require another library (librt),
  and leave persistent structures in a filesystem, which can fill up
  unexpectedly.
